{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Engineering with tf</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:03.602788. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# import liberary\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam    # for stream pipeline\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running Environment Setup for Cloud ML</h3>\n",
    "\n",
    "   - create unique project id on GCP storage\n",
    "   - single region bucket for saving and restoring model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:12.533803. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# set up vm environment\n",
    "import os\n",
    "REGION = 'us-central1'    # region of cloud storage bucket\n",
    "BUCKET = 'qwiklabs-gcp-0bb127b38c8a3a29'    # bucket name on the cloud ML engine\n",
    "PROJECT = 'qwiklabs-gcp-0bb127b38c8a3a29'    # project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:13.607775. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# bash environment\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:14.602763. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Pull Data from Big Query<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  SELECT \n",
      "  (tolls_amount + fare_amount) AS fare_amount,\n",
      "  DAYOFWEEK(pickup_datetime) AS dayofweek,\n",
      "  HOUR(pickup_datetime) AS hourofday,\n",
      "  pickup_longitude AS pickuplon,\n",
      "  pickup_latitude AS pickuplat,\n",
      "  dropoff_longitude AS dropofflon,\n",
      "  dropoff_latitude AS dropofflat,\n",
      "  passenger_count*1.0 AS passengers,\n",
      "  -- create unique key from pickup info\n",
      "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key\n",
      "FROM\n",
      "  [nyc-tlc:yellow.trips]\n",
      "WHERE\n",
      "  trip_distance > 0\n",
      "  AND fare_amount >= 2.5\n",
      "  AND pickup_longitude > -78    -- filter rides only within NYC\n",
      "  AND pickup_longitude < -70\n",
      "  AND dropoff_longitude > -78\n",
      "  AND dropoff_longitude < -70\n",
      "  AND pickup_latitude > 37\n",
      "  AND pickup_latitude < 45\n",
      "  AND dropoff_latitude > 37\n",
      "  AND dropoff_latitude < 45\n",
      "  AND passenger_count > 0\n",
      "   AND ABS(HASH(pickup_datetime)) % 100000 == 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:16.257556. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# select features from BQ\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  Args: data use, train, validation, test\n",
    "      phase: 1 = train, \n",
    "      phase: 2 = valid \n",
    "  Returnes: data table\n",
    "  \"\"\"\n",
    "  \n",
    "  # create bq query\n",
    "  base_query = \"\"\"\n",
    "  SELECT \n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  DAYOFWEEK(pickup_datetime) AS dayofweek,\n",
    "  HOUR(pickup_datetime) AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers,\n",
    "  -- create unique key from pickup info\n",
    "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78    -- filter rides only within NYC\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "  \n",
    "  # create train and valid data\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "    \n",
    "print(create_query(2, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h2> Preprocessing Dataflow job from BigQuery</h2>\n",
    "- use tf.transorm to preprocess and create data pipelie\n",
    "- create CSV file using Dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-8165c84c6121>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-8165c84c6121>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    gsutil -m rm -rf gs://$BUCKET/taxifare/ch4/taxi_preproc/\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:33:19.829774. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# run in from GCP\n",
    "%bash\n",
    "gsutil -m rm -rf gs://$BUCKET/taxifare/ch4/taxi_preproc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:40:04.479735. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# creare CSV\n",
    "def to_csv(rowdict):\n",
    "  import copy\n",
    "  days = ['null', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']   # null for no date\n",
    "  CSV_COLUMNS = 'fare_amount,dayofweek,hourofday,pickuplon,pickuplat,dropofflon,dropofflat,passengers,key'.split(',')\n",
    "  result = copy.deepcopy(rowdict)\n",
    "  result['dayofweek'] = days[result['dayofweek']]\n",
    "  return ','.join([str(result[k]) for k in CSV_COLUMNS])\n",
    "\n",
    "def preprocess_pipe(EVERy_N, RUNNER):\n",
    "  job_name = 'preprocess-taxifeatures' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "  print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "  OUTDIR_DIR = 'gs://{0}/taxifare/ch4/taxi_preproc'.format(BUCKET)\n",
    "  options = {\n",
    "    'staging_location': os.path.join(OUTDIR_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTDIR_DIR, 'tmp'),\n",
    "    'job_name': 'preprocess-taxifeatures' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "    'project': PROJECT,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flag=[], **options)\n",
    "  p = beam.Pipeline(RUNNER, options=opts)\n",
    "  for n, step in enumerate(['train', 'valid']):\n",
    "    query = create_query(n+1, EVERy_N)\n",
    "    outfile = os.path.join(OUTDIR_DIR, '{}.csv'.format(step))\n",
    "    (\n",
    "      p | 'read_{}'.format(step) >> beam.io.Read(beam.io.BigQuerySource(query=query))    # read file from BQ\n",
    "        | 'tocsv{}'.format(step) >> beam.Map(to_csv)   # apply transformation\n",
    "        | 'write{}'.format(step) >> beam.io.Write(beam.io.WriteToText(outfile))\n",
    "    )\n",
    "    \n",
    "  p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cloud vs. Local runs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job preprocess-taxifeatures-180519-234320 ... hang on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:43:20.989780. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/oauth2client/contrib/gce.py:99: UserWarning: You have requested explicit scopes to be used with a GCE service account.\n",
      "Using this argument will have no effect on the actual scopes for tokens\n",
      "requested. These scopes are set at VM instance creation time and\n",
      "can't be overridden in the request.\n",
      "\n",
      "  warnings.warn(_SCOPES_WARNING)\n",
      "WARNING:root:Dataset qwiklabs-gcp-0bb127b38c8a3a29:temp_dataset_aeaff4cb88064f4798723901c442d023 does not exist so we will create it as temporary with location=None\n",
      "WARNING:root:Dataset qwiklabs-gcp-0bb127b38c8a3a29:temp_dataset_9f11579c8bc141f48400edef27c7ecbd does not exist so we will create it as temporary with location=None\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/apache_beam/io/gcp/gcsio.py:113: DeprecationWarning: object() takes no parameters\n",
      "  super(GcsIO, cls).__new__(cls, storage_client))\n"
     ]
    }
   ],
   "source": [
    "preprocess_pipe(50*100000, 'DirectRunner')   # runs locally\n",
    "# preprocess_pipe(50*100000, 'DataflowRunner') # runs on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: \"ls\" command does not support \"file://\" URLs. Did you mean to use a gs:// URL?\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:45:03.656789. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls -l gsL//$BUCKET/taxifare/ch4/taxi_preproc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0,Wed,2,-73.991673,40.726478,-73.984347,40.766946,2.0,2013-06-05 02:48:26.000000-73.991740.726540.7669-73.9843\n",
      "7.3,Sat,3,-74.008527,40.72596,-73.99455,40.751717,2.0,2010-01-30 03:00:00.000000-74.008540.72640.7517-73.9946\n",
      "11.7,Sat,3,-73.98537,40.727553,-73.96169,40.77683,2.0,2010-01-30 03:00:00.000000-73.985440.727640.7768-73.9617\n",
      "20.5,Sat,3,-73.98921,40.730808,-73.959545,40.808858,2.0,2010-01-30 03:00:00.000000-73.989240.730840.8089-73.9595\n",
      "16.5,Sat,3,-73.982352,40.748493,-73.898938,40.74833,2.0,2010-01-30 03:00:00.000000-73.982440.748540.7483-73.8989\n",
      "22.9,Sat,3,-74.00181,40.733712,-73.921113,40.815263,2.0,2010-01-30 03:00:00.000000-74.001840.733740.8153-73.9211\n",
      "11.3,Sat,3,-73.92538,40.743755,-73.913053,40.705703,2.0,2010-01-30 03:00:00.000000-73.925440.743840.7057-73.9131\n",
      "16.5,Sat,3,-73.990418,40.760835,-74.007462,40.707177,2.0,2010-01-30 03:00:00.000000-73.990440.760840.7072-74.0075\n",
      "7.3,Sat,3,-73.97488,40.757017,-73.953557,40.78791,2.0,2010-01-30 03:00:00.000000-73.974940.75740.7879-73.9536\n",
      "26.1,Sat,3,-73.993993,40.746188,-73.924592,40.64468,2.0,2010-01-30 03:00:00.000000-73.99440.746240.6447-73.9246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:45:31.353806. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil cat \"gs://$BUCKET/taxifare/ch4/taxi_preproc/train.csv-00000-of-*\" | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Develop model with new inputs</h2>\n",
    "\n",
    "- download a fraction of the preprocessed data to enable local dev\n",
    "- the model in packaged in trainer folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘sample’: File exists\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/train.csv-00000-of-00001...\n",
      "/ [1 files][ 53.4 KiB/ 53.4 KiB]                                                \n",
      "Operation completed over 1 objects/53.4 KiB.                                     \n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/valid.csv-00000-of-00001...\n",
      "/ [1 files][  8.9 KiB/  8.9 KiB]                                                \n",
      "Operation completed over 1 objects/8.9 KiB.                                      \n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:49:57.767800. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash \n",
    "# get data from cloud storage\n",
    "mkdir sample\n",
    "gsutil cp \"gs://$BUCKET/taxifare/ch4/taxi_preproc/train.csv-00000-of-*\" sample/train.csv\n",
    "gsutil cp \"gs://$BUCKET/taxifare/ch4/taxi_preproc/valid.csv-00000-of-*\" sample/valid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_COLUMNS = [\r\n",
      "    # Define features\r\n",
      "    tf.feature_column.categorical_column_with_vocabulary_list('dayofweek', vocabulary_list = ['Sun', 'Mon', 'Tues', 'Wed', 'Thu', 'Fri', 'Sat']),\r\n",
      "    tf.feature_column.categorical_column_with_identity('hourofday', num_buckets = 24),\r\n",
      "\r\n",
      "    # Numeric columns\r\n",
      "    tf.feature_column.numeric_column('pickuplon'),\r\n",
      "    tf.feature_column.numeric_column('pickuplat'),\r\n",
      "    tf.feature_column.numeric_column('dropofflat'),\r\n",
      "    tf.feature_column.numeric_column('dropofflon'),\r\n",
      "    tf.feature_column.numeric_column('passengers'),\r\n",
      "    \r\n",
      "    # Engineered features that are created in the input_fn\r\n",
      "    tf.feature_column.numeric_column('latdiff'),\r\n",
      "    tf.feature_column.numeric_column('londiff'),\r\n",
      "    tf.feature_column.numeric_column('euclidean')\r\n",
      "]\r\n",
      "\r\n",
      "# Build the estimator\r\n",
      "def build_estimator(model_dir, nbuckets, hidden_units):\r\n",
      "    \"\"\"\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:57:49.015803. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# new crossed columns are added in model.py\n",
    "# see first 20 line on codes starting from \"INPUT_COLUMNS\n",
    "!grep -A 20 \"INPUT_COLUMNS =\" taxifare/trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def build_estimator(model_dir, nbuckets, hidden_units):\r\n",
      "    \"\"\"\r\n",
      "     Build an estimator starting from INPUT COLUMNS.\r\n",
      "     These include feature transformations and synthetic features.\r\n",
      "     The model is a wide-and-deep model.\r\n",
      "  \"\"\"\r\n",
      "\r\n",
      "    # Input columns\r\n",
      "    (dayofweek, hourofday, plon, plat, dlon, dlat, pcount, latdiff, londiff, euclidean) = INPUT_COLUMNS\r\n",
      "\r\n",
      "    # Bucketize the lats & lons\r\n",
      "    latbuckets = np.linspace(38.0, 42.0, nbuckets).tolist()\r\n",
      "    lonbuckets = np.linspace(-76.0, -72.0, nbuckets).tolist()\r\n",
      "    b_plat = tf.feature_column.bucketized_column(plat, latbuckets)\r\n",
      "    b_dlat = tf.feature_column.bucketized_column(dlat, latbuckets)\r\n",
      "    b_plon = tf.feature_column.bucketized_column(plon, lonbuckets)\r\n",
      "    b_dlon = tf.feature_column.bucketized_column(dlon, lonbuckets)\r\n",
      "\r\n",
      "    # Feature cross\r\n",
      "    ploc = tf.feature_column.crossed_column([b_plat, b_plon], nbuckets * nbuckets)\r\n",
      "    dloc = tf.feature_column.crossed_column([b_dlat, b_dlon], nbuckets * nbuckets)\r\n",
      "    pd_pair = tf.feature_column.crossed_column([ploc, dloc], nbuckets ** 4 )\r\n",
      "    day_hr =  tf.feature_column.crossed_column([dayofweek, hourofday], 24 * 7)\r\n",
      "\r\n",
      "    # Wide columns and deep columns.\r\n",
      "    wide_columns = [\r\n",
      "        # Feature crosses\r\n",
      "        dloc, ploc, pd_pair,\r\n",
      "        day_hr,\r\n",
      "\r\n",
      "        # Sparse columns\r\n",
      "        dayofweek, hourofday,\r\n",
      "\r\n",
      "        # Anything with a linear relationship\r\n",
      "        pcount \r\n",
      "    ]\r\n",
      "\r\n",
      "    deep_columns = [\r\n",
      "        # Embedding_column to \"group\" together ...\r\n",
      "        tf.feature_column.embedding_column(pd_pair, 10),\r\n",
      "        tf.feature_column.embedding_column(day_hr, 10),\r\n",
      "\r\n",
      "        # Numeric columns\r\n",
      "        plat, plon, dlat, dlon,\r\n",
      "        latdiff, londiff, euclidean\r\n",
      "    ]\r\n",
      "    \r\n",
      "    estimator = tf.estimator.DNNLinearCombinedRegressor(\r\n",
      "        model_dir = model_dir,\r\n",
      "        linear_feature_columns = wide_columns,\r\n",
      "        dnn_feature_columns = deep_columns,\r\n",
      "--\r\n",
      "    estimator = build_estimator(args['output_dir'], args['nbuckets'], args['hidden_units'].split(' '))\r\n",
      "    train_spec = tf.estimator.TrainSpec(\r\n",
      "        input_fn = read_dataset(\r\n",
      "            filename = args['train_data_paths'],\r\n",
      "            mode = tf.estimator.ModeKeys.TRAIN,\r\n",
      "            batch_size = args['train_batch_size']),\r\n",
      "        max_steps = args['train_steps'])\r\n",
      "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(\r\n",
      "        input_fn = read_dataset(\r\n",
      "            filename = args['eval_data_paths'],\r\n",
      "            mode = tf.estimator.ModeKeys.EVAL,\r\n",
      "            batch_size = args['eval_batch_size']),\r\n",
      "        steps = 100,\r\n",
      "        exporters = exporter)\r\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n",
      "\r\n",
      "# If we want to use TFRecords instead of CSV\r\n",
      "def gzip_reader_fn():\r\n",
      "    return tf.TFRecordReader(options=tf.python_io.TFRecordOptions(\r\n",
      "            compression_type = tf.python_io.TFRecordCompressionType.GZIP))\r\n",
      "\r\n",
      "def generate_tfrecord_input_fn(data_paths, num_epochs = None, batch_size = 512, mode = tf.estimator.ModeKeys.TRAIN):\r\n",
      "    def get_input_features():\r\n",
      "        # Read the tfrecords. Same input schema as in preprocess\r\n",
      "        input_schema = {}\r\n",
      "        if mode != tf.estimator.ModeKeys.INFER:\r\n",
      "            input_schema[LABEL_COLUMN] = tf.FixedLenFeature(shape = [1], dtype = tf.float32, default_value = 0.0)\r\n",
      "        for name in ['dayofweek', 'key']:\r\n",
      "            input_schema[name] = tf.FixedLenFeature(shape = [1], dtype = tf.string, default_value = 'null')\r\n",
      "        for name in ['hourofday']:\r\n",
      "            input_schema[name] = tf.FixedLenFeature(shape = [1], dtype = tf.int64, default_value = 0)\r\n",
      "        for name in SCALE_COLUMNS:\r\n",
      "            input_schema[name] = tf.FixedLenFeature(shape = [1], dtype = tf.float32, default_value = 0.0)\r\n",
      "\r\n",
      "        # How? \r\n",
      "        keys, features = tf.contrib.learn.io.read_keyed_batch_features(\r\n",
      "            data_paths[0] if len(data_paths) == 1 else data_paths,\r\n",
      "            batch_size,\r\n",
      "            input_schema,\r\n",
      "            reader = gzip_reader_fn,\r\n",
      "            reader_num_threads = 4,\r\n",
      "            queue_capacity = batch_size * 2,\r\n",
      "            randomize_input = (mode != tf.estimator.ModeKeys.EVAL),\r\n",
      "            num_epochs = (1 if mode == tf.estimator.ModeKeys.EVAL else num_epochs))\r\n",
      "        target = features.pop(LABEL_COLUMN)\r\n",
      "        features[KEY_FEATURE_COLUMN] = keys\r\n",
      "        return add_engineered(features), target\r\n",
      "\r\n",
      "    # Return a function to input the features into the model from a data path.\r\n",
      "    return get_input_features\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:58:27.902795. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# check build estimator model\n",
    "!grep -A 50 \"build_estimator\" taxifare/trainer/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def add_engineered(features):\r\n",
      "    # this is how you can do feature engineering in TensorFlow\r\n",
      "    lat1 = features['pickuplat']\r\n",
      "    lat2 = features['dropofflat']\r\n",
      "    lon1 = features['pickuplon']\r\n",
      "    lon2 = features['dropofflon']\r\n",
      "    latdiff = (lat1 - lat2)\r\n",
      "    londiff = (lon1 - lon2)\r\n",
      "    \r\n",
      "    # set features for distance with sign that indicates direction\r\n",
      "    features['latdiff'] = latdiff\r\n",
      "    features['londiff'] = londiff\r\n",
      "    dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\r\n",
      "    features['euclidean'] = dist\r\n",
      "    return features\r\n",
      "\r\n",
      "--\r\n",
      "    return tf.estimator.export.ServingInputReceiver(add_engineered(features), feature_placeholders)\r\n",
      "\r\n",
      "# Create input function to load data into datasets\r\n",
      "def read_dataset(filename, mode, batch_size = 512):\r\n",
      "    def _input_fn():\r\n",
      "        def decode_csv(value_column):\r\n",
      "            columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\r\n",
      "            features = dict(zip(CSV_COLUMNS, columns))\r\n",
      "            label = features.pop(LABEL_COLUMN)\r\n",
      "            return add_engineered(features), label\r\n",
      "        \r\n",
      "        # Create list of files that match pattern\r\n",
      "        file_list = tf.gfile.Glob(filename)\r\n",
      "\r\n",
      "        # Create dataset from file list\r\n",
      "        dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\r\n",
      "\r\n",
      "        if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "            num_epochs = None # indefinitely\r\n",
      "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\r\n",
      "        else:\r\n",
      "            num_epochs = 1 # end-of-input after this\r\n",
      "\r\n",
      "        dataset = dataset.repeat(num_epochs).batch(batch_size)\r\n",
      "        batch_features, batch_labels = dataset.make_one_shot_iterator().get_next()\r\n",
      "--\r\n",
      "        return add_engineered(features), target\r\n",
      "\r\n",
      "    # Return a function to input the features into the model from a data path.\r\n",
      "    return get_input_features\r\n",
      "\r\n",
      "def add_eval_metrics(labels, predictions):\r\n",
      "    pred_values = predictions['predictions']\r\n",
      "    return {\r\n",
      "        'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)\r\n",
      "    }\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-19 23:59:09.665812. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# check added features\n",
    "!grep -A 15 \"add_engineered(\" taxifare/trainer/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Run the new model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05ddb55a10>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05ddb55910>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-20-00:03:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-20-00:03:49\n",
      "INFO:tensorflow:Saving dict for global step 0: average_loss = 667.75476, global_step = 0, loss = 54088.137, rmse = 25.840952\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=string>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'euclidean': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'latdiff': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'londiff': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int32>, 'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=string>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'euclidean': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'latdiff': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'londiff': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int32>, 'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/model.ckpt-0\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/export/exporter/temp-1526774631/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /content/datalab/training-data-analyst/courses/machine_learning/feateng/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: None.\n",
      "WARNING:tensorflow:No new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/datalab/training-data-analyst/courses/machine_learning/feateng/taxifare/trainer/task.py\", line 124, in <module>\n",
      "    model.train_and_evaluate(arguments)\n",
      "  File \"/content/datalab/training-data-analyst/courses/machine_learning/feateng/taxifare/trainer/model.py\", line 183, in train_and_evaluate\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 439, in train_and_evaluate\n",
      "    executor.run()\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 518, in run\n",
      "    self.run_local()\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 663, in run_local\n",
      "    'Eval status: {}'.format(eval_result.status))\n",
      "RuntimeError: There was no new checkpoint after the training. Eval status: no new checkpoint\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:03:30.538333. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf taxifare.tar.gz taxi_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/taxifare\n",
    "  python -m trainer.task \\\n",
    "    --train_data_paths=\"${PWD}/sample/train\" \\\n",
    "    --eval_data_paths=${PWD}/sample/valid.csv \\\n",
    "    --output_dir=${PWD}/taxi_trained \\\n",
    "    --train_steps=1000 \\\n",
    "    --job-dir=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526774631\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:04:21.566783. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!ls taxi_trained/export/exporter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:04:56.185803. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%writefile /tmp/test.json\n",
    "{\"dayofweek\": \"Sun\", \"hourofday\": 17, \"pickuplon\": -73.885262, \"pickuplat\": 40.773008, \"dropofflon\": -73.987232, \"dropofflat\": 40.732403, \"passengers\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "[-15.447600364685059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:07:05.970774. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "model_dir=$(ls ${PWD}/taxi_trained/export/exporter)\n",
    "gcloud ml-engine local predict \\\n",
    "  --model-dir=${PWD}/taxi_trained/export/exporter/${model_dir} \\\n",
    "  --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train on Cloud</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Your current Cloud SDK version is: 200.0.0\n",
      "You will be upgraded to version: 201.0.0\n",
      "\n",
      "┌─────────────────────────────────────────────────┐\n",
      "│        These components will be updated.        │\n",
      "├──────────────────────────┬────────────┬─────────┤\n",
      "│           Name           │  Version   │   Size  │\n",
      "├──────────────────────────┼────────────┼─────────┤\n",
      "│ Cloud SDK Core Libraries │ 2018.05.11 │ 8.0 MiB │\n",
      "│ gcloud cli dependencies  │ 2018.05.11 │ 1.6 MiB │\n",
      "└──────────────────────────┴────────────┴─────────┘\n",
      "\n",
      "The following release notes are new in this upgrade.\n",
      "Please read carefully for information about new features, breaking changes,\n",
      "and bugs fixed.  The latest full release notes can be viewed at:\n",
      "  https://cloud.google.com/sdk/release_notes\n",
      "\n",
      "\u001b[m\u001b[1m201.0.0 (2018-05-15)\u001b[m\n",
      "\u001b[m  \u001b[1mBreaking Changes\u001b[m\n",
      "      ▪ **(Compute Engine)** Modified default TPU accelerator type to \u001b[1mv2-8\u001b[m\n",
      "        for \u001b[1mgcloud compute tpus\u001b[m commands. \u001b[1mtpu-v2\u001b[m has been deprecated.\n",
      "\n",
      "\u001b[m  \u001b[1mCloud Bigtable\u001b[m\n",
      "      ▪ Added the following commands to the \u001b[1mgcloud beta bigtable instances\u001b[m\n",
      "        command group to help manage IAM policies:\n",
      "        ◆ \u001b[1mset-iam-policy\u001b[m\n",
      "        ◆ \u001b[1mget-iam-policy\u001b[m\n",
      "        ◆ \u001b[1madd-iam-policy-binding\u001b[m\n",
      "        ◆ \u001b[1mremove-iam-policy-binding\u001b[m\n",
      "\n",
      "\u001b[m  \u001b[1mCloud Datalab\u001b[m\n",
      "      ▪ Updated the \u001b[1mdatalab\u001b[m component to the 20180503 release. Released\n",
      "        changes are documented in its tracking issue at\n",
      "        https://github.com/googledatalab/datalab/issues/1999\n",
      "        (https://github.com/googledatalab/datalab/issues/1999).\n",
      "\n",
      "\u001b[m  \u001b[1mCompute Engine\u001b[m\n",
      "      ▪ Promoted \u001b[1m--create-disk\u001b[m flag of \u001b[1mgcloud compute instances create\u001b[m to GA.\n",
      "        These flags allow creating new disks during instance creation.\n",
      "      ▪ Added the TYPE column to \u001b[1mgcloud compute interconnects attachments\n",
      "        list\u001b[m table format.\n",
      "      ▪ Added \u001b[1m--labels\u001b[m flag to \u001b[1mgcloud beta compute instance-templates\n",
      "        create-with-container\u001b[m.\n",
      "\n",
      "\u001b[m  \u001b[1mFirebase Test Lab\u001b[m\n",
      "      ▪ Firebase Test Lab now supports mobile app testing for iOS. Please\n",
      "        request access here:\n",
      "        https://docs.google.com/forms/d/e/1FAIpQLSf5cx1ot8ndHU9YrFkCn6gPoQZLxgW_6H13e_bot3he90n7Ng/viewform\n",
      "        (https://docs.google.com/forms/d/e/1FAIpQLSf5cx1ot8ndHU9YrFkCn6gPoQZLxgW_6H13e_bot3he90n7Ng/viewform).\n",
      "        Added the following commands:\n",
      "        ◆ \u001b[1mgcloud beta firebase test ios models <list|describe>\u001b[m\n",
      "        ◆ \u001b[1mgcloud beta firebase test ios versions <list|describe>\u001b[m\n",
      "        ◆ \u001b[1mgcloud alpha firebase test ios run\u001b[m\n",
      "\n",
      "\u001b[m  \u001b[1mKubernetes Engine\u001b[m\n",
      "      ▪ Promoted \u001b[1m--enable-stackdriver-kubernetes\u001b[m of \u001b[1mgcloud container clusters\n",
      "        create\u001b[m to beta.\n",
      "\n",
      "    Subscribe to these release notes at\n",
      "    https://groups.google.com/forum/#!forum/google-cloud-sdk-announce\n",
      "    (https://groups.google.com/forum/#!forum/google-cloud-sdk-announce).\n",
      "\u001b[m\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "╠═ Creating update staging area                             ═╣\n",
      "╠════════════════════════════════════════════════════════════╣\n",
      "╠═ Uninstalling: Cloud SDK Core Libraries                   ═╣\n",
      "╠════════════════════════════════════════════════════════════╣\n",
      "╠═ Uninstalling: gcloud cli dependencies                    ═╣\n",
      "╠════════════════════════════════════════════════════════════╣\n",
      "╠═ Installing: Cloud SDK Core Libraries                     ═╣\n",
      "╠════════════════════════════════════════════════════════════╣\n",
      "╠═ Installing: gcloud cli dependencies                      ═╣\n",
      "╠════════════════════════════════════════════════════════════╣\n",
      "╠═ Creating backup and activating new installation          ═╣\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "\n",
      "Performing post processing steps...done.                                       \n",
      "\n",
      "Update done!\n",
      "\n",
      "To revert your SDK to the previously installed version, you may run:\n",
      "  $ gcloud components update --version 200.0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:10:09.516792. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!gcloud --quiet components update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained us-central1 lab4a_180520_001104\n",
      "jobId: lab4a_180520_001104\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [lab4a_180520_001104] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe lab4a_180520_001104\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs lab4a_180520_001104\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:11:04.126558. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/taxifare/ch4/taxi_trained\n",
    "JOBNAME=lab4a_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=${PWD}/taxifare/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=BASIC \\\n",
    "  --runtime-version=1.4 \\\n",
    "  -- \\\n",
    "  --train_data_paths=\"gs://$BUCKET/taxifare/ch4/taxi_preproc/train*\" \\\n",
    "  --eval_data_paths=\"gs://${BUCKET}/taxifare/ch4/taxi_preproc/valid*\"  \\\n",
    "  --train_steps=5000 \\\n",
    "  --output_dir=$OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6. Hyper-parameter tune </h2>\n",
    "\n",
    "<ol>\n",
    "<li> train_batch_size: 512 </li>\n",
    "<li> nbuckets: 16 </li>\n",
    "<li> hidden_units: \"64 64 64 8\" </li>    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run Cloud training on 2 million row dataset </h1>\n",
    "\n",
    "This run uses as input 2 million rows and takes ~20 minutes with 10 workers (STANDARD_1 pricing tier). The model is exactly the same as above. The only changes are to the input (to use the larger dataset) and to the Cloud MLE tier (to use STANDARD_1 instead of BASIC -- STANDARD_1 is approximately 10x more powerful than BASIC). Because the Dataflow preprocessing takes about 15 minutes, we train here using CSV files in a public bucket.\n",
    "\n",
    "When doing distributed training, use train_steps instead of num_epochs. The distributed workers don't know how many rows there are, but we can calculate train_steps = num_rows \\* num_epochs / train_batch_size. In this case, we have 2141023 * 100 / 512 = 418168 train steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/feateng2m us-central1 lab4a_180520_001236\n",
      "jobId: lab4a_180520_001236\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: WARNING: command not found\n",
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [lab4a_180520_001236] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe lab4a_180520_001236\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs lab4a_180520_001236\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:12:35.997799. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WARNING -- this uses significant resources and is optional. Remove this line to run the block.\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/taxifare/feateng2m\n",
    "JOBNAME=lab4a_$(date -u +%y%m%d_%H%M%S)\n",
    "TIER=STANDARD_1 \n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/taxifare/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=$TIER \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://cloud-training-demos/taxifare/train*\" \\\n",
    "   --eval_data_paths=\"gs://cloud-training-demos/taxifare/valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=418168 \\\n",
    "   --train_batch_size=512 --nbuckets=16 --hidden_units=\"64 64 64 8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/feateng2m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 7006. Click <a href=\"/_proxy/45719/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7006"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:12:46.336814. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "OUTDIR='gs://{0}/taxifare/feateng2m'.format(BUCKET)\n",
    "print OUTDIR\n",
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/seaborn/categorical.py:338: DeprecationWarning: pandas.core.common.is_categorical_dtype is deprecated. import from the public API: pandas.api.types.is_categorical_dtype instead\n",
      "  elif is_categorical(y):\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/seaborn/categorical.py:1424: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family [u'sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFYCAYAAACYmm95AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAg4r+ShHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ceabbcd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:13:22.087814. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({'Lab' : pd.Series(['1a', '2-3', '4a', '4b', '4c']),\n",
    "              'Method' : pd.Series(['Heuristic Benchmark', 'tf.learn', '+Feature Eng.', '+ Hyperparam', '+ 2m rows']),\n",
    "              'RMSE': pd.Series([8.026, 9.4, 8.3, 5.0, 3.03]) })\n",
    "\n",
    "ax = sns.barplot(data = df, x = 'Method', y = 'RMSE')\n",
    "ax.set_ylabel('RMSE (dollars)')\n",
    "ax.set_xlabel('Labs/Methods')\n",
    "plt.plot(np.linspace(-20, 120, 1000), [5] * 1000, 'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/train.csv-00000-of-00001 [Content-Type=text/plain]...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/valid.csv-00000-of-00001 [Content-Type=text/plain]...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/eval/events.out.tfevents.1526775153.cmle-training-9020182672160085571...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/checkpoint...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/events.out.tfevents.1526775142.cmle-training-9020182672160085571...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/train.csv-00000-of-00001...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/eval/events.out.tfevents.1526775153.cmle-training-9020182672160085571...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_preproc/valid.csv-00000-of-00001...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/checkpoint...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/events.out.tfevents.1526775142.cmle-training-9020182672160085571...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/variables/variables.data-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/saved_model.pb...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/variables/variables.index...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/graph.pbtxt...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.data-00000-of-00001...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/variables/variables.data-00000-of-00001...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/graph.pbtxt...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/variables/variables.index...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/export/exporter/1526775155/saved_model.pb...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.index...\n",
      "Copying gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.meta...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.data-00000-of-00001...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.meta...\n",
      "Removing gs://qwiklabs-gcp-0bb127b38c8a3a29/taxifare/ch4/taxi_trained/model.ckpt-1.index...\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-05-20 00:13:45.634791. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil -m mv gs://${BUCKET}/taxifare/ch4/  gs://${BUCKET}/taxifare/ch4_1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

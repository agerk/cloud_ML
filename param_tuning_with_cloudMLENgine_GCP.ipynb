{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter tuning with Cloud MLEngine </h2>\n",
    "\n",
    "** Objective**\n",
    "- Instead of hand tuning of hyperparameters to improve model accuracy, setup cloud ML to do tuining  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load liberaries and setup compute environment\n",
    "import os\n",
    "PROJECT = 'qwiklabs-gcp-5720bb7433a520e9'   # project name\n",
    "BUCKET = 'qwiklabs-gcp-5720bb7433a520e9'    # bucket name\n",
    "REGION = 'us-central1'   # should be consisten with the BUCKET zone\n",
    "os.environ['TFVERSION'] = '1.8'   # latest Tensorflow version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup environment for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create command-line program </h2>\n",
    "\n",
    "**Step 1**: In order for CloudML to d automatic hyperparameter tuning, we need to create command-line argument for those hyperparameters we desire to fine-tune\n",
    "\n",
    "**Step 2**: To submit jobs in jobs in parallel, we need to create a distributed training program. **tf.Estimator** will just do that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf trainer_2\n",
    "mkdir trainer_2   # create a folder for trainer for packaging-up the modle\n",
    "touch trainer_2/__init__.py    # create __init__.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create reate model house.py for predicting median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer_2/house.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer_2/house.py   \n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# create train\n",
    "def train(output_dir, batch_size, learning_rate):\n",
    "  tf.loging.set_verbosity(tf.logging.INFO)\n",
    "  \n",
    "  # read dataset and split into train and eval\n",
    "  df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "  df[\"num_rooms\"] = df['total_rooms'] / df['households']\n",
    "  # create train and validation set\n",
    "  msk = np.random.rand(len(df)) < 0.8\n",
    "  train_df = df[msk]\n",
    "  eval_df = df[~msk]\n",
    "  \n",
    "  # input pipeline for train and evaluation\n",
    "  train_input_fn = tf.estimator.inputs.pandas_input_fn(x= train_df[[\"num_rooms\"]],\n",
    "                                                      y = train_df[\"median_house_value\"]/ SCALE,\n",
    "                                                      num_epochs = 1,\n",
    "                                                      batch_size = batch_size, \n",
    "                                                      shutil = True)\n",
    "  \n",
    "  eval_input_fn = tf.estimator.inputs.pandas_input_fn(x= train_df[[\"num_rooms\"]],\n",
    "                                                      y = eval_df[\"median_house_value\"]/ SCALE,\n",
    "                                                      num_epochs = 1,\n",
    "                                                      batch_size = len(eval_df), \n",
    "                                                      shutil = False)\n",
    "  # define feature columns\n",
    "  features = [tf.feature_column.numeric_column('num_rooms')]\n",
    "  \n",
    "  def train_and_evaluate(out_dir):\n",
    "    # get number of steps, since tf igonore epochs\n",
    "    num_steps = (len(train_df) / batch_size) / learning_rate\n",
    "    \n",
    "    # create custom optimzer\n",
    "    my_opt = tf.train.FtrlOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    # the rest of the estimator is as usual\n",
    "    estimator = tf.estimator.LinearRegressor(model_dir = output_dir,\n",
    "                                            feature_column = features,\n",
    "                                            optimizer = my_opt)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn, \n",
    "                                       max_steps = num_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn, \n",
    "                                       steps = None)\n",
    "    tf.estimator.train_and_evaluate(estimator. train_spec, eval_spec)\n",
    "    \n",
    "    # run the training \n",
    "    shutil.rmtree(output_dir, ignore_errors=True)    # start fresh\n",
    "    train_and_evaluate(output_dir)\n",
    "if __name__ == '__main__' and \"get_ipython\" not in dir():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "    '--learning_rate',    # tuneable hyperparameter passed as command-line arg \n",
    "    type = float,\n",
    "    defualt = 0.01\n",
    "  )\n",
    "  \n",
    "  parser.add_argument(\n",
    "    '--batch_size',    # tuneable hyperparameter passed as command-line arg\n",
    "    type = int,\n",
    "    defualy = 30\n",
    "  ),\n",
    "  parser.add_argument(\n",
    "    '--job-dir',\n",
    "    help = 'GCS location to write checkpoints and export models.',\n",
    "    required = True\n",
    "  )\n",
    "  args = parser.parse_args()\n",
    "  print(\"Writing checkpoints to {}\".format(args.job_dir))\n",
    "  train(args.job_dir, args.batch_size, args.learning_rate)\n",
    "                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/content/datalab/training-data-analyst/courses/machine_learning/deepdive/05_artandscience/trainer_2/house.py\", line 62, in <module>\n",
      "    defualt = 0.01\n",
      "  File \"/usr/local/envs/py2env/lib/python2.7/argparse.py\", line 1294, in add_argument\n",
      "    action = action_class(**kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'defualt'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf house_trained_2\n",
    "gcloud ml-engine local train \\\n",
    "  --module-name=trainer_2.house \\\n",
    "  --job-dir=house_trained_2 \\\n",
    "  --package-path=$(pwd)/trainer_2 \\\n",
    "  -- \\\n",
    "  --batch_size=30 \\\n",
    "  --learning_rate=0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create hyperparam.yaml</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrails: 1\n",
    "    hyperparameterMetricTag: average_loss\n",
    "    params:\n",
    "      - parameterName: batch_size\n",
    "        type: INTEGER\n",
    "        miniValue: 8\n",
    "        maxValue: 64\n",
    "        scaleType: UNIT_LINEAR_SCALE\n",
    "      - parameterName: learning_rate\n",
    "        type: DOUBLE\n",
    "        minValue: 0.01\n",
    "        maxValue: 0.1\n",
    "        scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-5720bb7433a520e9/house_trained_2/packages/22c3dbe05a95fee0e4706a187ceca1b06cd9b79ee345ed20e1bb9d4714ae9bc6/trainer_2-0.0.0.tar.gz#1527303630035075...\n",
      "/ [1 objects]                                                                   \r\n",
      "Operation completed over 1 objects.                                              \n",
      "ERROR: (gcloud.ml-engine.jobs.submit.training) INVALID_ARGUMENT: Invalid JSON payload received. Unknown name \"max_parallel_trails\" at 'job.training_input.hyperparameters': Cannot find field.\n",
      "Invalid JSON payload received. Unknown name \"mini_value\" at 'job.training_input.hyperparameters.params[0]': Cannot find field.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: \"Invalid JSON payload received. Unknown name \\\"max_parallel_trails\\\"\\\n",
      "      \\ at 'job.training_input.hyperparameters': Cannot find field.\"\n",
      "    field: job.training_input.hyperparameters\n",
      "  - description: \"Invalid JSON payload received. Unknown name \\\"mini_value\\\" at 'job.training_input.hyperparameters.params[0]':\\\n",
      "      \\ Cannot find field.\"\n",
      "    field: job.training_input.hyperparameters.params[0]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/house_trained_2\n",
    "gsutil rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training house_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  --module-name=trainer.house \\\n",
    "  --package-path=$(pwd)/trainer_2 \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --runtime-version=$TFVERSION \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !gcloud ml-engine jobs describe job_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
